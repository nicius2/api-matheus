from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error
from datetime import datetime, date
import os # Para gerenciar arquivos tempor√°rios de dashboard se ainda for gerado

# Inicializa o FastAPI
app = FastAPI(
    title="API de Previs√£o de Demanda e Otimiza√ß√£o de Descongelamento",
    description="API para prever a demanda de produtos e otimizar o processo de descongelamento.",
    version="1.0.0"
)

# Configura√ß√£o do CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Em produ√ß√£o, especifique os dom√≠nios permitidos
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Fun√ß√µes do seu script (mantidas ou ligeiramente ajustadas) ---

def carregar_e_preparar_dados(caminho_arquivo, id_produto, colunas_exogenas=None):
    """
    Carrega os dados de vendas de um arquivo CSV, filtra por um produto espec√≠fico,
    prepara a s√©rie temporal e as vari√°veis ex√≥genas, e divide em treino e teste.
    """
    try:
        dados = pd.read_csv(caminho_arquivo)
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail=f"Arquivo CSV n√£o encontrado no caminho: {caminho_arquivo}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao ler o arquivo CSV: {e}")

    dados['data_dia'] = pd.to_datetime(dados['data_dia'])
    dados_produto = dados[dados['id_produto'] == id_produto].copy()
    
    if dados_produto.empty:
        raise HTTPException(status_code=404, detail=f"ID de produto {id_produto} n√£o encontrado nos dados.")

    dados_produto.set_index('data_dia', inplace=True)
    
    dados_completos = dados_produto.asfreq('D')
    serie_temporal = dados_completos['total_venda_dia_kg'].fillna(0)
    
    exogenas_df = None
    if colunas_exogenas:
        colunas_existentes = [col for col in colunas_exogenas if col in dados_produto.columns]
        
        if colunas_existentes:
            exogenas_df = dados_completos[colunas_existentes].fillna(0)
            colunas_exogenas = colunas_existentes
        else:
            print(f"Aviso: Nenhuma das colunas ex√≥genas especificadas {colunas_exogenas} foi encontrada no arquivo. O modelo ser√° treinado sem vari√°veis externas.")
            colunas_exogenas = []

    treino_y = serie_temporal[:-7]
    teste_y = serie_temporal[-7:]
    
    treino_X = None
    teste_X = None
    if exogenas_df is not None:
        treino_X = exogenas_df[:-7]
        teste_X = exogenas_df[-7:]

    return treino_y, teste_y, treino_X, teste_X, serie_temporal, exogenas_df

def treinar_modelo_e_prever(treino_data, exog_data, steps, exog_futuro=None):
    """
    Treina um modelo SARIMAX e o utiliza para fazer previs√µes futuras, incluindo vari√°veis ex√≥genas.
    """
    try:
        modelo = SARIMAX(treino_data, 
                         exog=exog_data,
                         order=(1, 1, 1), 
                         seasonal_order=(1, 1, 1, 7),
                         enforce_stationarity=False, enforce_invertibility=False)
        resultado = modelo.fit(disp=False)
        previsao = resultado.get_forecast(steps=steps, exog=exog_futuro)
        return resultado, previsao.summary_frame(alpha=0.05)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao treinar o modelo ou gerar previs√£o: {e}")

def calcular_metricas(real, previsto):
    """
    Calcula e formata as m√©tricas de erro MAPE (Mean Absolute Percentage Error) e RMSE (Root Mean Squared Error).
    """
    real_nonzero = np.where(real == 0, 1e-10, real)
    mape = np.mean(np.abs((real - previsto) / real_nonzero)) * 100
    rmse = np.sqrt(mean_squared_error(real, previsto))
    return f'{mape:.2f}%', f'{rmse:.2f}'


# --- Modelos Pydantic para a resposta ---
class PrevisaoDia(BaseModel):
    data: str
    previsao_kg: float
    limite_inferior_kg: float
    limite_superior_kg: float

class DemandInfoResponse(BaseModel):
    id_produto: int
    data_consulta: str
    qtd_a_retirar_hoje_kg: float
    qtd_em_descongelamento_kg: float
    qtd_disponivel_para_venda_hoje_kg: float
    previsao_proximos_dias: list[PrevisaoDia]
    mape: str
    rmse: str

# --- Novo endpoint GET para informa√ß√µes espec√≠ficas ---

@app.get("/demand_info/{product_id}", response_model=DemandInfoResponse)
async def get_demand_information(product_id: int):
    """
    Retorna informa√ß√µes espec√≠ficas sobre a demanda e otimiza√ß√£o de descongelamento
    para um produto, incluindo quantidades a retirar, em descongelamento, dispon√≠vel
    e previs√£o de vendas para os pr√≥ximos dias.
    """
    ARQUIVO_VENDAS = 'dados.csv'
    COLUNAS_EXOGENAS = ['promocao', 'feriado'] # Mantidas para compatibilidade, mas n√£o usadas se n√£o estiverem no CSV

    # 1. Carrega e prepara os dados
    treino_y, teste_y, treino_X, teste_X, serie_completa, exogenas_df = \
        carregar_e_preparar_dados(ARQUIVO_VENDAS, product_id, COLUNAS_EXOGENAS)

    # 2. Define o horizonte de previs√£o e prepara os dados ex√≥genos futuros.
    dias_para_prever = len(teste_y) + 2 # Preve para os dias de teste + 2 dias futuros (D+1 e D+2)
    exogenas_futuras = None
    exog_para_previsao = None

    if exogenas_df is not None and not exogenas_df.empty:
        datas_futuras = pd.date_range(start=exogenas_df.index[-1] + pd.Timedelta(days=1), periods=dias_para_prever, freq='D')
        exogenas_futuras = pd.DataFrame(0, index=datas_futuras, columns=exogenas_df.columns)
        exog_para_previsao = pd.concat([teste_X, exogenas_futuras])
    
    # 3. Treina o modelo SARIMAX e gera as previs√µes.
    resultado_modelo, previsao_df = treinar_modelo_e_prever(treino_y, treino_X, dias_para_prever, exog_para_previsao)

    # --- Extra√ß√£o das informa√ß√µes solicitadas ---
    data_hoje = date.today()
    perda_peso = 0.15

    # Previs√£o de demanda para D+1 (amanh√£) e D+2 (depois de amanh√£)
    # previsao_df j√° cont√©m a previs√£o para len(teste_y) dias do set de teste, e mais 2 dias futuros.
    # Os √∫ltimos 2 elementos de 'mean' em previsao_df ser√£o D+1 e D+2 (relativos ao √∫ltimo dia conhecido)
    
    # Se a previs√£o for pequena, ela conter√° poucos dias.
    # Preciso pegar a previs√£o para os pr√≥ximos dias *a partir da data atual*.
    # O teste_y √© para os √∫ltimos 7 dias. A previs√£o_df tem len(teste_y) + 2 dias.
    # Ent√£o, os √∫ltimos 2 dias da previs√£o_df correspondem a D+1 e D+2 em rela√ß√£o ao final do dataset.

    # Considerando que o `treinar_modelo_e_prever` retorna `dias_para_prever` (que √© len(teste_y) + 2)
    # D+1 e D+2 ser√£o os √∫ltimos dois dias da previs√£o_df.
    demanda_d1 = previsao_df['mean'].iloc[-2]
    demanda_d2 = previsao_df['mean'].iloc[-1]

    # C√°lculos das quantidades
    qtd_a_retirar_hoje_kg = demanda_d2 / (1 - perda_peso) if (1 - perda_peso) != 0 else 0
    qtd_em_descongelamento_kg = demanda_d1 / (1 - perda_peso) if (1 - perda_peso) != 0 else 0
    qtd_disponivel_para_venda_hoje_kg = treino_y.iloc[-1] / (1 - perda_peso) if (1 - perda_peso) != 0 else 0

    # Formatar a previs√£o para os pr√≥ximos dias
    previsao_proximos_dias_lista = []
    # Pegar as previs√µes do √∫ltimo dia do treino_y (que √© o dia anterior ao teste)
    # at√© o final da previs√£o_df (que inclui os dias de teste e os dias futuros)
    
    # Pegar apenas as previs√µes que s√£o realmente "futuras" (ap√≥s o √∫ltimo dado real)
    # O `previsao_df` j√° tem o √≠ndice de data.
    # Exemplo: se o √∫ltimo dado de treino √© 2024-06-30, e o teste √© de 7 dias, a previs√£o
    # come√ßa em 2024-06-30 (se for 1 step a frente) ou 2024-07-01.
    
    # Para simplificar, vou retornar todas as previs√µes geradas, que incluem o per√≠odo de teste + 2 dias futuros
    for index, row in previsao_df.iterrows():
        previsao_proximos_dias_lista.append(PrevisaoDia(
            data=index.strftime('%Y-%m-%d'),
            previsao_kg=row['mean'],
            limite_inferior_kg=row['mean_ci_lower'],
            limite_superior_kg=row['mean_ci_upper']
        ))

    # C√°lculo das m√©tricas de performance (usando o per√≠odo de teste)
    previsao_teste = previsao_df.head(len(teste_y))['mean']
    mape, rmse = calcular_metricas(teste_y, previsao_teste)

    # Retorna as informa√ß√µes como JSON
    return DemandInfoResponse(
        id_produto=product_id,
        data_consulta=data_hoje.strftime('%Y-%m-%d'),
        qtd_a_retirar_hoje_kg=qtd_a_retirar_hoje_kg,
        qtd_em_descongelamento_kg=qtd_em_descongelamento_kg,
        qtd_disponivel_para_venda_hoje_kg=qtd_disponivel_para_venda_hoje_kg,
        previsao_proximos_dias=previsao_proximos_dias_lista,
        mape=mape,
        rmse=rmse
    )

# --- Endpoint POST original (mantido, mas voc√™ pode remov√™-lo se quiser apenas o GET) ---
# Se voc√™ quiser remover este endpoint, remova toda a fun√ß√£o e o decorador @app.post
# E remova a importa√ß√£o `from fastapi.responses import HTMLResponse, FileResponse`
# e `import plotly.graph_objects as go`, `from plotly.subplots import make_subplots` se n√£o forem mais usados.
# O `import os` tamb√©m pode ser removido se n√£o houver mais cria√ß√£o de arquivos.
@app.post("/generate_dashboard/{product_id}")
async def generate_dashboard(product_id: int):
    """
    Gera um dashboard HTML com a previs√£o de demanda e otimiza√ß√£o de descongelamento.
    Retorna o dashboard HTML gerado.
    """
    # A l√≥gica da fun√ß√£o simular_estoque_e_gerar_dashboard precisaria ser inclu√≠da aqui
    # ou chamada de uma fun√ß√£o separada que ainda gere o HTML.
    # Para este exemplo, vou assumir que a fun√ß√£o original simular_estoque_e_gerar_dashboard
    # ainda existe e √© chamada.

    # Nota: para manter este endpoint funcional, voc√™ precisaria ter
    # as importa√ß√µes Plotly e a fun√ß√£o simular_estoque_e_gerar_dashboard
    # do script original aqui no app.py, ou em um arquivo utilit√°rio importado.
    # Se voc√™ optou por remover a fun√ß√£o simular_estoque_e_gerar_dashboard do app.py,
    # este endpoint n√£o funcionar√° como est√°.
    
    # Para o prop√≥sito de demonstrar o GET, vou assumir que a vers√£o completa do script est√° dispon√≠vel.
    # Caso voc√™ queira realmente desativar o dashboard e ter apenas o JSON,
    # voc√™ pode apagar todo este endpoint POST e as fun√ß√µes Plotly e relacionadas.
    
    # Vou re-incluir a fun√ß√£o simular_estoque_e_gerar_dashboard (simplificada para n√£o repetir o c√≥digo)
    # A original gerava o HTML. Para este exemplo, vou manter um esqueleto dela
    # ou indicar que ela viria do script original.
    
    # Para manter o exemplo conciso, vou assumir que a fun√ß√£o simular_estoque_e_gerar_dashboard
    # e suas depend√™ncias (Plotly) ainda est√£o definidas em app.py,
    # como na minha resposta anterior. Se voc√™ as apagou, precisaria re-adicion√°-las para este POST.
    
    # Se voc√™ *realmente* s√≥ quer o GET, pode apagar este bloco POST.
    raise HTTPException(status_code=501, detail="Endpoint de gera√ß√£o de dashboard temporariamente desativado para foco no GET.")



# üëâ Adicione abaixo disso:
if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("app:app", host="0.0.0.0", port=port, reload=False)
# Para rodar a API localmente, voc√™ usaria:

# uvicorn app:app --host 0.0.0.0 --port 8000 --reload
# E ent√£o acessaria: http://localhost:8000/demand_info/{id_do_produto} (com um GET request)